{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf667a0",
   "metadata": {},
   "source": [
    "### A few interesting things that came out of the fitting exercise..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4077c06e",
   "metadata": {},
   "source": [
    "#### Why do the XGB with/without z-scaling give identical results?\n",
    "\n",
    "* Tree-based models like XGBoost are invariant to monotonic transformations of the features, including z-scoring.\n",
    "* StandardScaler just subtracts the mean and divides by std — it doesn’t change splitting behavior, because splits are based on thresholds (e.g., \"is feature > 6.5?\").\n",
    "* Unless you use a model that’s sensitive to feature scale (like logistic regression, SVM, or neural networks), or combine tree-based methods with regularization strategies that interact with scale (rare in XGBoost), you’ll see nearly identical performance with or without scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d43fcb",
   "metadata": {},
   "source": [
    "#### What is the best possible performance the model could hope to achieve, given the noise added?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a371a861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6818\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data(path='../output/emotion_data.csv'):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def calculate_stochastic_bayes_accuracy(df, n_trials=10000, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    prob_cols = ['happy_prob', 'energetic_prob', 'engaged_prob']\n",
    "    class_labels = ['Happy', 'Energetic', 'Engaged']\n",
    "\n",
    "    probs = df[prob_cols].values\n",
    "    true_labels = df['predicted_emotion'].values\n",
    "\n",
    "    correct = 0\n",
    "    for _ in range(n_trials):\n",
    "        i = np.random.randint(len(df))\n",
    "        p = probs[i]\n",
    "        sampled_label = np.random.choice(class_labels, p=p)\n",
    "        if sampled_label == true_labels[i]:\n",
    "            correct += 1\n",
    "\n",
    "    return correct / n_trials\n",
    "\n",
    "df = load_data()\n",
    "print(calculate_stochastic_bayes_accuracy(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce12b05e",
   "metadata": {},
   "source": [
    "```\n",
    "Classification report for xgb_nozscore:\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.67      0.72      0.69       660\n",
    "           1       0.63      0.62      0.62       624\n",
    "           2       0.62      0.58      0.60       716\n",
    "\n",
    "    accuracy                           0.64      2000\n",
    "   macro avg       0.64      0.64      0.64      2000\n",
    "weighted avg       0.64      0.64      0.64      2000\n",
    "```\n",
    "\n",
    "The accuracy value of 0.64 above is the direct comparator to the Bayes-optimal simulated accuracy of 0.68\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22ad8e4",
   "metadata": {},
   "source": [
    "Understanding how the Bayes-optimal simulation works:\n",
    "\n",
    "---\n",
    "\n",
    "Let’s take a sample row:\n",
    "\n",
    "happy_prob\tenergetic_prob\tengaged_prob\tpredicted_emotion\n",
    "0.45\t0.40\t0.15\tHappy\n",
    "\n",
    "We run this trial:\n",
    "\n",
    "Pick this row: index i = 5\n",
    "\n",
    "Extract p = [0.45, 0.40, 0.15]\n",
    "\n",
    "Run sampled_label = np.random.choice(class_labels, p=p)\n",
    "\n",
    "With 45% chance, it gives 'Happy'\n",
    "\n",
    "With 40% chance, it gives 'Energetic'\n",
    "\n",
    "With 15% chance, it gives 'Engaged'\n",
    "\n",
    "Compare sampled_label to true_labels[5] (which is 'Happy')\n",
    "\n",
    "If they're the same, count it as correct.\n",
    "\n",
    "You repeat this process 10,000 times across randomly sampled rows from the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "If the label 'Happy' was always overwhelmingly likely (like p = [0.95, 0.03, 0.02]), it would be correct most of the time — and so would your model.\n",
    "\n",
    "If the label was more ambiguous (e.g., [0.36, 0.34, 0.30]), then even the best model might guess wrong.\n",
    "\n",
    "The final accuracy (e.g. 68%) reflects the level of noise or uncertainty in your data-generating process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PDP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
